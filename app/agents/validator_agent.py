from __future__ import annotations

import json
import os
import logging
from typing import List, Optional
from pydantic import BaseModel, Field
from openai import AsyncOpenAI
# Import TaskContext and context tools from server
from app.context import TaskContext, get_task_id, log_action
from agents import Agent
from agents import WebSearchTool, function_tool, OpenAIChatCompletionsModel, handoff, GuardrailFunctionOutput, RunContextWrapper, output_guardrail
from dotenv import load_dotenv

# Import existing tools
from app.swizzy_tools import (
    create_document,
    extract_text_from_image,
    ponder_document_request,
    read_file_content,
)
from app.tools import (
    analyze_spreadsheet,
    create_spreadsheet,
    modify_spreadsheet,
    ponder_spreadsheet_request,
)
from app.tools.content_tools import (
    convert_pdf_to_markdown,
    convert_to_markdown,
    read_markdown,
    edit_markdown_section,
    analyze_content_structure,
    convert_file_format,
    create_markdown
)
from app.tools.web_tools import (
    read_url,
    extract_url_to_markdown,
    search_web,
    search_with_budget,
    reset_search_budget,
    get_search_cost_summary
)
from app.tools.research_tools import (
    plan_research,
    execute_research_plan,
    research_topic
)
from app.tools.data_extraction_tools import (
    extract_structured_data,
    convert_json_to_excel,
    extract_invoice_to_excel,
    extract_table_from_document
)
from app.tools.memory_tools import (
    store_memory,
    retrieve_memory,
    update_memory,
    delete_memory,
    search_memories,
    store_link,
    get_links_by_tag
)
from app.tools.core_tools import ponder_task
from app.config import STYLE_INSTRUCTIONS

logger = logging.getLogger(__name__)

# Load environment variables if not already loaded
load_dotenv()

# Verify environment variables and setup OpenAI client for Gemini
api_key = os.getenv("GOOGLE_API_KEY") # Assuming Gemini uses GOOGLE_API_KEY based on prior context
base_url = os.getenv("OPENAI_BASE_URL") # Assuming a proxy/custom base URL

if not api_key or not base_url:
    raise ValueError("Missing required environment variables: GOOGLE_API_KEY and OPENAI_BASE_URL must be set")

# Create custom OpenAI client
client = AsyncOpenAI(
    api_key=api_key,
    base_url=base_url
)

# Create the model configuration for Gemini
gemini_model = OpenAIChatCompletionsModel(
    model="gemini-1.5-flash", # Updated to 1.5-flash as per previous context, adjust if needed
    openai_client=client,
)

# --- Define Output Model ---
class SwizzyOutput(BaseModel):
    reasoning: str = Field(description="Brief reasoning for the chosen action (tool use or handoff).")
    action_taken: str = Field(description="Description of the action performed (e.g., 'Used read_file_content', 'Handed off to spreadsheet_agent', 'Executed analysis script').")
    outcome: str = Field(description="Summary of the outcome (e.g., 'Success', 'Completed analysis', 'Error occurred', 'Handoff initiated').")
    response_to_user: str = Field(description="The final message to convey to the user.")
    generated_handles: Optional[List[str]] = Field(default=None, description="List of new file handles generated by a specialist agent, if any.")
    error_details: Optional[str] = Field(default=None, description="Details of any error encountered during tool use or handoff, if applicable.")
    task_context_id: Optional[str] = Field(default=None, description="Unique ID for the current task context, if available.")

# Validator Agent Configuration - Updated with TaskContext and tools
validator_agent = Agent[TaskContext]( # <--- Added TaskContext type hint
    name="Validator Agent",
    model=gemini_model,
    instructions="".join([
        "You are a Validator Agent, specialized in evaluating the success of completed tasks. ",
        "Your goal is to review task outcomes, compare them against success criteria, and provide ",
        "objective assessments of task completion. ",
        "You MUST log your validation findings using the `log_action` tool. ",
        "You can use `get_task_id` to reference the task being validated in logs or memory.",
         # ...(rest of instructions remain the same)...
        "**WORKFLOW**: ",
        "1. When asked to validate a task, first retrieve the original plan and success criteria (use retrieve_memory/search_memories). ",
        "2. Review the task outcomes and deliverables (use read_file_content/read_markdown). ",
        "3. Compare the outcomes against the success criteria. ",
        "4. Assess the level of task completion. ",
        "5. Identify any gaps or areas for improvement. ",
        "6. Recommend next steps based on your assessment. ",
        "7. Log your validation assessment using log_action.",
        "8. Store your detailed validation results in memory using store_memory.",
         # ...(rest of instructions remain the same)...
         "**IMPORTANT: LOGGING ACTIONS AND DECISIONS**",
        "- ALWAYS log your significant validation decisions using the log_action tool",
        "- Use store_memory for detailed reasoning or complex state preservation."

    ]),
    tools=[
         # Context Tools FIRST
        get_task_id,
        log_action,
        # Core/Pondering Tools
        ponder_task,
        # Memory tools
        store_memory,
        retrieve_memory,
        update_memory,
        delete_memory,
        search_memories,
        store_link,
        get_links_by_tag,
        # Content tools
        read_markdown,
        # File tools
        read_file_content
    ],
)

from __future__ import annotations

import json
import os
import logging
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field
from openai import AsyncOpenAI
# Import TaskContext and context tools from server
from app.context import TaskContext, get_task_id, log_action, inspect_context, get_files
from agents import Agent, function_tool
from agents import WebSearchTool, OpenAIChatCompletionsModel, handoff, GuardrailFunctionOutput, RunContextWrapper, output_guardrail
from dotenv import load_dotenv

# Import existing tools
from app.swizzy_tools import (
    create_document,
    extract_text_from_image,
    ponder_document_request,
    read_file_content,
    extract_spreadsheet_from_document,
)
from app.tools import (
    analyze_spreadsheet,
    create_spreadsheet,
    modify_spreadsheet,
    ponder_spreadsheet_request,
)
from app.tools.content_tools import (
    convert_pdf_to_markdown,
    convert_to_markdown,
    read_markdown,
    edit_markdown_section,
    analyze_content_structure,
    convert_file_format,
    create_markdown
)
from app.tools.web_tools import (
    read_url,
    extract_url_to_markdown,
    search_web,
    search_with_budget,
    reset_search_budget,
    get_search_cost_summary
)
from app.tools.research_tools import (
    plan_research,
    execute_research_plan,
    research_topic
)
from app.tools.data_extraction_tools import (
    extract_structured_data,
    convert_json_to_excel,
    extract_invoice_to_excel,
    extract_table_from_document
)
from app.tools.memory_tools import (
    store_memory,
    retrieve_memory,
    update_memory,
    delete_memory,
    search_memories,
    store_link,
    get_links_by_tag
)
from app.tools.core_tools import ponder_task
from app.config import STYLE_INSTRUCTIONS
from app.agents.model_config import gemini_model  # Import shared model config
from app.services.script_execution_service import ScriptExecutionService

logger = logging.getLogger(__name__)


# --- Define Output Model ---
class SwizzyOutput(BaseModel):
    reasoning: str = Field(description="Brief reasoning for the chosen action (tool use or handoff).")
    action_taken: str = Field(description="Description of the action performed (e.g., 'Used read_file_content', 'Handed off to spreadsheet_agent', 'Executed analysis script').")
    outcome: str = Field(description="Summary of the outcome (e.g., 'Success', 'Completed analysis', 'Error occurred', 'Handoff initiated').")
    response_to_user: str = Field(description="The final message to convey to the user.")
    generated_handles: Optional[List[str]] = Field(default=None, description="List of new file handles generated by a specialist agent, if any.")
    error_details: Optional[str] = Field(default=None, description="Details of any error encountered during tool use or handoff, if applicable.")
    task_context_id: Optional[str] = Field(default=None, description="Unique ID for the current task context, if available.")


# Define tool to log file details
@function_tool
def log_file_details(file_handle: str, description: str) -> str:
    """Logs the file handle and description of a file."""
    log_action(action_description=f"File: {file_handle}, Description: {description}")
    return f"Logged file details: {file_handle} - {description}"


# Define tool for running custom analysis
@function_tool
def run_custom_analysis(spreadsheet_file: str, task: str, input_schema: str, output_requirements: str) -> str:
    """Generates and executes a python script to perform a specific task on a spreadsheet"""
    script_execution_service = ScriptExecutionService()
    # Read the spreadsheet file
    spreadsheet_content = script_execution_service._safe_read_file(spreadsheet_file)
    if not spreadsheet_content:
        return "Error: Could not read spreadsheet file"

    # Generate the script
    script = script_execution_service.generate_script(task, input_schema, output_requirements)
    if not script:
        return "Error: Could not generate script"

    # Prepare input data
    input_data: Dict[str, Any] = {"spreadsheet_file": spreadsheet_file}

    # Execute the script
    execution_result = script_execution_service.execute_script(script, input_data)

    if not execution_result.get("success"):
        return f"Error: Script execution failed: {execution_result.get('error')}"

    return json.dumps(execution_result.get("output"))


# Agent for Spreadsheet Analysis
spreadsheet_analysis_agent = Agent[TaskContext](
    name="Spreadsheet Analysis Specialist",
    instructions="".join([
        "You are a specialist in spreadsheet analysis, capable of extracting insights and generating comprehensive reports.",
        "You are also capable of generating and executing custom python scripts to perform specialized analysis.",
        "Your primary responsibility is to thoroughly analyze spreadsheet files and create well-structured Markdown reports summarizing your findings.",
        "You MUST use the \`get_task_id\` tool to get the current task ID and prepend it to any filename you create (e.g., \`[task_id]_analysis_report.md\`).",
        "You MUST log all significant actions and decisions using the \`log_action\` tool.",
        "Always use inspect context to view and log all availabel files so you can work with all fileds",
        "Before taking ANY action, you MUST:",
        "1. Use the \`ponder_task\` tool to analyze the request and determine the best approach.",
        "2. Log this pondering action using \`log_action\`.",
        "3. Follow the recommended approach from pondering.",
        "Your workflow must ALWAYS follow this sequence:",
        "1. PONDER: Use \`ponder_spreadsheet_request\` to think through the request and determine the best approach.",
        "2. LOG PONDERING: Use \`log_action\` to record the pondering outcome.",
        "3. READ: Use \`read_file_content\` to read the spreadsheet file.",
        "4. ANALYZE: Use \`analyze_spreadsheet\`, custom scripts (if provided), and other tools to analyze the data.",
        "5. LOG ANALYSIS: Use \`log_action\` to record the analysis steps and findings.",
        "6. REPORT: Create a Markdown report summarizing the analysis using \`create_markdown\`.",
        "7. UPLOAD: Store the report using \`storage_service\` and log the file details.",
        "8. RESPOND: Provide a comprehensive response to the client with the report file handle and a summary of the analysis.",
        "You have these tools at your disposal:",
        "- \`get_task_id\`: MUST be called before creating files to get the task ID for the filename.",
        "- \`log_action\`: MUST be called to log pondering, analysis, and report creation actions.",
        "- \`ponder_spreadsheet_request\`: MUST be called FIRST to think through the request.",
        "- \`read_file_content\`: Use this to read the spreadsheet file.",
        "- \`analyze_spreadsheet\`: Use this to perform complex analysis operations on spreadsheets.",
        "- \`create_markdown\`: Use this to create the analysis report (filename MUST be \`[task_id]_analysis_report.md\`).",
        "- \`log_file_details\`: Log the file handle and description of the created report.",
        "- \`inspect_context\`: Inspect context.",
        "- \`get_files\`: Get all files.",
        "- \`run_custom_analysis\`: Generates and executes a python script to perform a specific task on a spreadsheet.",
        "You should use inspect context to validate the accurate file handle passed to you. If you can't find a file handle there is likely an issue and you must terminate the process.",
        "When creating the analysis report, ensure it includes:",
        "- A clear summary of the analysis goals and approach.",
        "- Key findings and insights from the data.",
        "- Visualizations or tables to support your findings (if possible).",
        "- Recommendations or next steps based on the analysis.",
        "- The file handler of the analysed file to complete the task. Do not forget this. Always. Always. Always.",
        "- Always include the original file name into the description and never forget to include it. Never. Never. Never.",
        "IMPORTANT: Always remember to include the file handler of the spread sheet you analysed in the final output.",
        "IMPORTANT: If there are file handler in the context that relate to the spreadsheet file you must use those handlers.",
    ]),
    model=gemini_model,
    tools=[
        # Context Tools FIRST
        get_task_id,
        log_action,
        inspect_context,
        get_files,
        # Core/Pondering Tools
        ponder_task,
        # Spreadsheet tools
        read_file_content,
        analyze_spreadsheet,
        create_markdown,
        log_file_details,
        ponder_spreadsheet_request,
        # Scripting tools
        run_custom_analysis,
    ],
)
